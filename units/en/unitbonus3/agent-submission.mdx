# DIAMBRA Competition Platform

<img src="https://raw.githubusercontent.com/diambra/.github/master/img/platform.jpg" alt="Unit bonus 3 thumbnail"/>

Our competition platform allows you to submit your agents and compete with other coders around the globe in epic video games tournaments!

It features a public global leaderboard where users are ranked by the best score achieved by their agents in our different environments.

It also offers you the possibility to unlock cool achievements depending on the performances of your agent.

Submitted agents are evaluated and their episodes are streamed on our Twitch channel.

We aimed at making the submission process as smooth as possible, try it now! You find all the details in the sub-pages linked below.

## Basic Agent Script

The central element of a submission is the agent python script. Its structure is always composed by two main parts: the preparation step, where the agent and the environment setup is completed, and the interaction loop, where the classical agent-environment interaction happens.

After a first call to the reset method, you start iterating alternating action selection and environment stepping, resetting the environment when the episode is done. That's it, we take care of the rest.

There is one thing that is worth noticing: since we want your submission to be the same no matter how many episodes are needed to evaluate it, you need to implement the while loop in a way that it keeps iterating indefinitely (`while True:`) and only exits (the `break` statement) when the value `info["env_done"]` is true. This value is set by us and used to let the agent know that the evaluation has been completed. In this way, the same script can be used to run evaluations made of 3, 5, 10 or whatever number of episodes you want, without changing a single line.

```python
#!/usr/bin/env python3
import diambra.arena
from diambra.arena import SpaceTypes, Roles, EnvironmentSettings

# Settings
settings = EnvironmentSettings()
settings.step_ratio = 6
settings.frame_shape = (128, 128, 1)
settings.role = Roles.P2
settings.difficulty = 4
settings.action_space = SpaceTypes.MULTI_DISCRETE

env = diambra.arena.make("sfiii3n", settings)
observation, info = env.reset()

while True:
    action = env.action_space.sample()
    observation, reward, terminated, truncated, info = env.step(action)

    if terminated or truncated:
        observation, info = env.reset()
        if info["env_done"]:
            break

# Close the environment
env.close()
```

## How To Submit An Agent

The basic process to submit an agent consists in the following steps:

1. Write a python script in which your agent interact with the environment exactly as if you were performing evaluation in your local machine
2. Store your trained agent's scripts and weights (if any) in a private repository and create a personal access token to the repository (in our examples we will use GitHub).
3. Submit the agent using our Command Line Interface specifying your private repository files path, your secret token and one of the public pre-built dependencies images we provide

{{% notice tip %}}
In our <a href="https://github.com/diambra/agents" target="_blank">DIAMBRA Agents repo</a> we provide many examples, ranging from a trivial random agent to RL agents trained with state-of-the-art RL libraries.
{{% /notice %}}

In the subsections linked below, we guide you through this process, starting from the easiest use case and building upon it to show you how to leverage the most advanced features.

### Submit Pre-Built Agents

To get the feeling of how an agent submission works, you can leverage our pre-built agents. In <a href="https://github.com/diambra/agents" target="_blank">DIAMBRA Agents repo</a>, together with different source code examples, we also provide <a href="https://github.com/orgs/diambra/packages?repo_name=agents" target="_blank">pre-built docker images (packages)</a> for some of them.

For example, <a href="https://github.com/diambra/agents/pkgs/container/agent-random-1" target="_blank">here</a> you find the pre-built docker image for the random agent correspondent to <a href="https://github.com/diambra/agents/blob/main/basic/random_1/agent.py" target="_blank">this</a> source code. As indicated by the python script settings, this random agent will play using a "Random" character in a random game.

Using this pre-built docker image you can easily perform your first submission ever on DIAMBRA platform, and appear in the official online leaderboard by simply typing in your preferred shell the following command:

```shell
diambra agent submit diambra/agent-random-1:main
```
{{% notice note %}}
If you want to specify the game on which to run the random agent, use the `--gameId` command line argument that our pre-built image accepts, when submitting the docker image as follows: `diambra agent submit diambra/agent-random-1:main --gameId tektagt`. Additional similar use cases are covered in the <a href="../../argumentsandcommands/">"Arguments and Commands"</a> page.
{{% /notice %}}

After running the command, you will receive a submission confirmation, its identification number as well as the url where to see the results, something similar to the following:

```
diambra agent submit diambra/agent-random-1:main
üñ•Ô∏è  (178) Agent submitted: https://diambra.ai/submission/178
```

{{% notice note %}}
By default, the submission will select the lowest difficulty level (`Easy`) of the three available (`Easy`, `Medium`, `Hard`). To change this, you can add the `--submission.difficulty` argument: `diambra agent submit --submission.difficulty Medium diambra/agent-random-1:main`
{{% /notice %}}


{{% notice warning %}}
As shown here, it is possible to embed your agent files (i.e. scripts and weights) in the dependencies docker image and submit only that. Keep in mind that this image needs to be public and will be visible on the platform, so every user will be able to use it for his own submissions.
{{% /notice %}}

### Submit Your Own Agent

Finally, after the agent training is completed, besides running it locally in your own machine, you may want to submit it to our <a href="../../competitionplatform">Competition Platform!</a> To do so, you can use the following script that provides a ready to use, flexible example that can accommodate different models, games and settings.

{{% notice tip %}}
To submit your trained agent to our platform, compete for the first leaderboard positions, and unlock our achievements, follow the simple steps described in the <a href="../../competitionplatform/howtosubmitanagent/">"How to Submit an Agent"</a> section.
{{% /notice %}}

```python
import os
import yaml
import json
import argparse
from diambra.arena import Roles, SpaceTypes, load_settings_flat_dict
from diambra.arena.stable_baselines3.make_sb3_env import make_sb3_env, EnvironmentSettings, WrappersSettings
from stable_baselines3 import PPO

"""This is an example agent based on stable baselines 3.

Usage:
diambra run python stable_baselines3/agent.py --cfgFile $PWD/stable_baselines3/cfg_files/doapp/sr6_128x4_das_nc.yaml --trainedModel "model_name"
"""

def main(cfg_file, trained_model, test=False):
    # Read the cfg file
    yaml_file = open(cfg_file)
    params = yaml.load(yaml_file, Loader=yaml.FullLoader)
    print("Config parameters = ", json.dumps(params, sort_keys=True, indent=4))
    yaml_file.close()

    base_path = os.path.dirname(os.path.abspath(__file__))
    model_folder = os.path.join(base_path, params["folders"]["parent_dir"], params["settings"]["game_id"],
                                params["folders"]["model_name"], "model")

    # Settings
    params["settings"]["action_space"] = SpaceTypes.DISCRETE if params["settings"]["action_space"] == "discrete" else SpaceTypes.MULTI_DISCRETE
    settings = load_settings_flat_dict(EnvironmentSettings, params["settings"])
    settings.role = Roles.P1

    # Wrappers Settings
    wrappers_settings = load_settings_flat_dict(WrappersSettings, params["wrappers_settings"])
    wrappers_settings.normalize_reward = False

    # Create environment
    env, num_envs = make_sb3_env(settings.game_id, settings, wrappers_settings, no_vec=True)
    print("Activated {} environment(s)".format(num_envs))

    # Load the trained agent
    model_path = os.path.join(model_folder, trained_model)
    agent = PPO.load(model_path)

    # Print policy network architecture
    print("Policy architecture:")
    print(agent.policy)

    obs, info = env.reset()

    while True:
        action, _ = agent.predict(obs, deterministic=False)

        obs, reward, terminated, truncated, info = env.step(action.tolist())

        if terminated or truncated:
            obs, info = env.reset()
            if info["env_done"] or test is True:
                break

    # Close the environment
    env.close()

    # Return success
    return 0

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--cfgFile", type=str, required=True, help="Configuration file")
    parser.add_argument("--trainedModel", type=str, default="model", help="Model checkpoint")
    parser.add_argument("--test", type=int, default=0, help="Test mode")
    opt = parser.parse_args()
    print(opt)

    main(opt.cfgFile, opt.trainedModel, bool(opt.test))
```

How to run it locally:

```shell
diambra run python agent.py --cfgFile /absolute/path/to/config.yaml --trainedModel "model_name"
```

and the configuration file to be used is the same that was used for training it, like the one reported in the previous paragraph.



